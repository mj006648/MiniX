# spark-jobs/02-pipeline-schedule.yaml

# --- 작업 1: 데이터 품질 검증 (매시간 0분에 실행) ---
apiVersion: sparkoperator.k8s.io/v1beta2
kind: ScheduledSparkApplication
metadata:
  name: parking-validation-schedule
  namespace: spark-operator
spec:
  schedule: "0 * * * *" # 매시간 0분
  concurrencyPolicy: Forbid
  successfulRunHistoryLimit: 3
  failedRunHistoryLimit: 3
  template:
    type: Python
    mode: cluster
    # [중요] 제공해주신 이미지 사용 (이 이미지에는 Iceberg, Nessie 등 필요 라이브러리가 모두 포함되어 있어야 함)
    image: "ich6648/spark-iceberg-nessie-kafka:9.0"
    imagePullPolicy: Always
    # 실행할 메인 파이썬 스크립트 파일 (ConfigMap에서 마운트된 경로)
    mainApplicationFile: "local:///mnt/scripts/data_validator.py"
    sparkVersion: "3.5.0"
    driver:
      serviceAccount: spark-sa
      cores: 1
      memory: "1g"
      # Secret에 저장된 S3 접속 정보를 환경 변수로 주입
      envFrom:
        - secretRef:
            name: s3-creds-for-spark
      # ConfigMap을 Pod 내부의 /mnt/scripts 디렉토리에 마운트
      volumeMounts:
        - name: scripts-volume
          mountPath: /mnt/scripts
    executor:
      instances: 2
      cores: 1
      memory: "1g"
      envFrom:
        - secretRef:
            name: s3-creds-for-spark
      volumeMounts:
        - name: scripts-volume
          mountPath: /mnt/scripts
    # 사용할 볼륨 정의 (소스는 위에서 만든 ConfigMap)
    volumes:
      - name: scripts-volume
        configMap:
          name: spark-scripts
---
# --- 작업 2: Main 브랜치 병합 (매시간 10분에 실행) ---
apiVersion: sparkoperator.k8s.io/v1beta2
kind: ScheduledSparkApplication
metadata:
  name: parking-merge-to-main-schedule
  namespace: spark-operator
spec:
  schedule: "10 * * * *" # 검증 작업 후 10분 뒤 실행
  concurrencyPolicy: Forbid
  successfulRunHistoryLimit: 3
  failedRunHistoryLimit: 3
  template:
    type: Python
    mode: cluster
    image: "ich6648/spark-iceberg-nessie-kafka:9.0" # 동일한 이미지 사용
    mainApplicationFile: "local:///mnt/scripts/merge_to_main.py"
    sparkVersion: "3.5.0"
    driver:
      serviceAccount: spark-sa
      cores: 1
      memory: "512m"
      volumeMounts:
        - name: scripts-volume
          mountPath: /mnt/scripts
    executor:
      instances: 0 # 병합 작업은 익스큐터가 필요 없음 (리소스 절약)
    volumes:
      - name: scripts-volume
        configMap:
          name: spark-scripts
