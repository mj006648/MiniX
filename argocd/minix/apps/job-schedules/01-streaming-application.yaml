# FILE: argocd/minix/apps/job-schedules/01-streaming-application.yaml

apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: dynamic-all-in-one-processor
  namespace: spark-operator
spec:
  type: Python
  mode: cluster
  image: "ich6648/spark-iceberg-nessie-kafka:9.0"
  imagePullPolicy: Always
  mainApplicationFile: "local:///mnt/scripts/dynamic_all_in_one_processor.py"
  sparkVersion: "3.5.0"
  restartPolicy:
    type: Always
  driver:
    serviceAccount: spark-sa
    cores: 1
    memory: "1g"
    envFrom:
      - secretRef:
          name: s3-creds-for-streaming-spark
    volumeMounts:
      - name: scripts-volume
        mountPath: /mnt/scripts
    # --- ▼▼▼ [핵심] 이 부분을 드라이버에 추가합니다 ▼▼▼ ---
    hostAliases:
    - ip: "10.34.48.242" # kafka-0-lb의 EXTERNAL-IP
      hostnames:
      - "b0.minix.local"
    - ip: "10.34.48.244" # kafka-1-lb의 EXTERNAL-IP
      hostnames:
      - "b1.minix.local"
    - ip: "10.34.48.246" # kafka-2-lb의 EXTERNAL-IP
      hostnames:
      - "b2.minix.local"
    # --- ▲▲▲ 여기까지 ▲▲▲ ---
  executor:
    instances: 2
    cores: 1
    memory: "1g"
    envFrom:
      - secretRef:
          name: s3-creds-for-streaming-spark
    volumeMounts:
      - name: scripts-volume
        mountPath: /mnt/scripts
    # --- ▼▼▼ [핵심] 이 부분도 익스큐터에 동일하게 추가합니다 ▼▼▼ ---
    hostAliases:
    - ip: "10.34.48.242"
      hostnames:
      - "b0.minix.local"
    - ip: "10.34.48.244"
      hostnames:
      - "b1.minix.local"
    - ip: "10.34.48.246"
      hostnames:
      - "b2.minix.local"
    # --- ▲▲▲ 여기까지 ▲▲▲ ---
  volumes:
    - name: scripts-volume
      configMap:
        name: spark-scripts
