# s3-sink-connector.yaml
apiVersion: platform.confluent.io/v1beta1
kind: KafkaConnector
metadata:
  name: s3-sink-parking-events
  namespace: confluent
spec:
  class: "io.confluent.connect.s3.S3SinkConnector"
  kafkaClusterRef:
    name: kafka
  # ★★★ 중요: Connect 클러스터가 배포되어야 이 커넥터가 실행될 수 있습니다.
  connectClusterRef:
    name: connect
  maxTasks: 2
  configs:
    "connector.class": "io.confluent.connect.s3.S3SinkConnector"
    "topics": "parking-entries,parking-exits"
    "format.class": "io.confluent.connect.s3.format.parquet.ParquetFormat"
    
    # --- ★★★ 사용자 요청사항 1: 100개 메시지마다 S3에 쓰기 ★★★ ---
    "flush.size": "100"
    
    "storage.class": "io.confluent.connect.s3.storage.S3Storage"
    "s3.bucket.name": "iceberg"
    "store.url": "http://rook-ceph-rgw-my-store.rook-ceph.svc:80"
    "access.key.id": "LDCMT684CGVXV6P4E0HA"
    "secret.access.key": "E9dfgciqiyWMD0ukBXT638pY5CggcP7Ble7eBdeu"
    
    "topics.dir": "landing"
    "partitioner.class": "io.confluent.connect.storage.partitioner.TimeBasedPartitioner"
    
    # --- ★★★ 사용자 요청사항 2: 파티션을 1일 단위로 생성 ★★★ ---
    "path.format": "'year'=YYYY/'month'=MM/'day'=dd"
    # 1일 = 24시간 * 60분 * 60초 * 1000밀리초 = 86,400,000 밀리초
    "partition.duration.ms": "86400000"
    
    "locale": "ko_KR"
    "timezone": "Asia/Seoul"
    "timestamp.extractor": "Record"
